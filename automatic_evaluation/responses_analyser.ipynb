{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c613106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from pydracor import DraCorAPI\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b28c833",
   "metadata": {},
   "source": [
    "## 1. Loading experiments results from JSON files to a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491d4476",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_PREFIXES = [\n",
    "    \"1-1\",\n",
    "    \"1-2\",\n",
    "    \"1-3\",\n",
    "    \"1-4\",\n",
    "    \"1-5\",\n",
    "    \"3-1\",\n",
    "    \"4-1\",\n",
    "    \"4-2\",\n",
    "    \"4-3\",\n",
    "    \"4-4\",\n",
    "    \"5-1\",\n",
    "    \"5-2\",\n",
    "    \"5-3\",\n",
    "    \"5-4\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f6b4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = 'haiku-4-5' #choose this for haiku-4-5\n",
    "model = 'sonnet-4' # choose this for sonnet-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c873674b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the uploaded files\n",
    "path = f\"results/{model}/extracted/*.json\" \n",
    "\n",
    "rows = []\n",
    "\n",
    "for file in glob.glob(path):\n",
    "    with open(file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    filename = os.path.basename(file)\n",
    "    \n",
    "    # Experiment ID is always the first part before the first \"_\"\n",
    "    experiment_id = filename.split(\"_\")[0]  # e.g. \"1-1\"\n",
    "\n",
    "    # Extract the `response` field (if missing, set to None)\n",
    "    response = data.get(\"response\", None)\n",
    "    tool_chain = data.get(\"tool_chain\", None)\n",
    "    success = data.get(\"success\", False)\n",
    "    valid = data.get(\"valid\", False)\n",
    "\n",
    "    rows.append({\n",
    "        \"filename\": filename,\n",
    "        \"experiment_id\": experiment_id,\n",
    "        \"success\": success,\n",
    "        \"response\": response,\n",
    "        \"valid\": valid,\n",
    "        \"tool_chain\": tool_chain,\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d2d7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['experiment_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2f5547",
   "metadata": {},
   "source": [
    "### Basic stats on how many successful / failed runs \n",
    "\n",
    "(testing for 'request failure', step 1 in Henny's diagram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0898533",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_attempts = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbae11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['success'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a75566",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_suscesses = df['success'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af351941",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['tool_chain'].str.len()>0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f2ea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tool_chains = df[df['tool_chain'].str.len()>0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec8d650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid True or null\n",
    "df[df['valid']!=False].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a9ac7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_invalid = df[(df['valid']!=False) & (df['success']==True)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c596155c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(\n",
    "    number=[total_attempts, total_suscesses, total_tool_chains, not_invalid],\n",
    "    stage=[\"Total attempts\", \"Total success (got response)\", \"Total Tool Chain Uses\", \"Valid Responses (or open questions)\"])\n",
    "\n",
    "# color_discrete_map={\n",
    "#         \"Total attempts\": \"#636EFA\",\n",
    "#         \"Total success (got response)\": \"#00CC96\",\n",
    "#         \"Total Tool Chain Uses\": \"#AB63FA\",\n",
    "#         \"Valid Responses (or open questions)\": \"#FFA15A\"\n",
    "#     }\n",
    "\n",
    "fig = px.funnel(data, x='number', y='stage', title=model.title(), \n",
    "                #color=\"stage\", \n",
    "                #color_discrete_map=color_discrete_map\n",
    "                )\n",
    "fig.update_layout(title_font_size=14, title_x=0.5)  # optional tweaks\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933b953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['success']==True]['valid'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5284cf80",
   "metadata": {},
   "source": [
    "## 2. Post-processing LLM responses for better automatic evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d494afbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_last_number(s):\n",
    "    if s is None:\n",
    "        return None\n",
    "    # find all groups of digits\n",
    "    nums = re.findall(r\"\\d+\", str(s))\n",
    "    if not nums:\n",
    "        return None\n",
    "    return int(nums[-1])  # take the last one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f00136",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"numeric_response\"] = df[\"response\"].apply(extract_last_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3225ea3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1605ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_numbers(s):\n",
    "    if s is None:\n",
    "        return []\n",
    "    # find all groups of digits\n",
    "    nums = re.findall(r\"\\d+\", str(s))\n",
    "    return [int(n) for n in nums]  # convert to ints\n",
    "\n",
    "df[\"all_numbers\"] = df[\"response\"].apply(extract_all_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4b5e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['experiment_id']=='1-5'][['filename', 'response', 'numeric_response', 'all_numbers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413d0b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['experiment_id']=='1-5'][['response', 'numeric_response', 'all_numbers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5d659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28fa2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats = (\n",
    "#     df_filtered.groupby(\"experiment_id\")[\"numeric_response\"]\n",
    "#       .agg([\"count\", \"mean\", \"std\", \"var\", \"min\", \"max\"])\n",
    "# )\n",
    "\n",
    "# # add range as max-min\n",
    "# stats[\"range\"] = stats[\"max\"] - stats[\"min\"]\n",
    "\n",
    "# stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a069896",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"experiment_id\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2ad75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"experiment_id\")[\"numeric_response\"].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb23c2f9",
   "metadata": {},
   "source": [
    "### Normalise responses to select-the-corpus questions (3-1, 3-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a4615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalised response will contain the same as numeric_response for numeric questions \n",
    "# but also corpus slugs for 'which corpus' questions\n",
    "df['normalised_response'] = df['numeric_response'].astype('string')\n",
    "df['normalised_response'] = df['normalised_response'].str.replace('.0$', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0912e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['normalised_response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1b1c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should all be replaced by the corpus slugs \n",
    "df[df['experiment_id'].isin(['3-1', '3-2'])]['normalised_response']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba299d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "crpra = DraCorAPI().get_corpora()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b69b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "slugs = [corpus.name for corpus in crpra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4f1648",
   "metadata": {},
   "outputs": [],
   "source": [
    "_pattern = re.compile(r'\\b(?:' + '|'.join(slugs) + r')\\b', flags=re.IGNORECASE)\n",
    "\n",
    "def find_last_corpus_slug(text: str) -> str | None:\n",
    "    \"\"\"Return the last DraCor slug mentioned as a whole word, or None.\"\"\"\n",
    "    last = None\n",
    "    for match in _pattern.finditer(text):\n",
    "        last = match.group(0).lower()  # normalize to lowercase slug\n",
    "    return last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba38f0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['experiment_id'].isin(['3-1', '3-2'])\n",
    "df.loc[mask, 'normalised_response'] = df.loc[mask, 'response'].apply(find_last_corpus_slug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cc0a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['experiment_id'].isin(['3-1', '3-2'])][['success','response','normalised_response']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324e339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['experiment_id'].isin(['3-1', '3-2']) & df['success']==True)][['experiment_id','success','response','normalised_response']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b1e2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"results/compiled_responses.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4369430d",
   "metadata": {},
   "source": [
    "## 3. Loading manually-defined correct responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66f9e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = pd.read_csv(\"preliminary_work/compiled_manual_answers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b00eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa06998",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_dict = dict(zip(correct[\"ID\"], correct[\"Correct Answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63afc48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['correct_answer'] = df['experiment_id'].map(correct_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab28957",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3bc8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[['experiment_id', 'numeric_response', 'correct_answer']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e745c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_strictly_numeric = df[df['experiment_id'].str.startswith('1-') | \n",
    "                         df['experiment_id'].str.startswith('2-') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a42d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_strictly_numeric.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5499cc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_strictly_numeric[['experiment_id', 'numeric_response', 'correct_answer']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1064e725",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_strictly_numeric[df_strictly_numeric['experiment_id'] == '1-3']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a1cacb",
   "metadata": {},
   "source": [
    "## 4. Evaluating correctness of the LLM response (hit & miss table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f05794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_miss(df, with_emojis=True):\n",
    "    df = df.copy()\n",
    "    df[\"is_correct\"] = df[\"normalised_response\"] == df[\"correct_answer\"]\n",
    "    df[\"iteration\"] = df.groupby(\"experiment_id\").cumcount() + 1\n",
    "\n",
    "    if with_emojis:\n",
    "        df[\"emoji\"] = df[\"is_correct\"].map({1: \"✅\", 0: \"❌\"})\n",
    "        hit_table = (\n",
    "            df.pivot(index=\"experiment_id\", columns=\"iteration\", values=\"emoji\")\n",
    "            .sort_index()\n",
    "            .sort_index(axis=1)\n",
    "        )\n",
    "    else:\n",
    "        hit_table = (\n",
    "            df.pivot(index=\"experiment_id\", columns=\"iteration\", values=\"is_correct\")\n",
    "            .sort_index()\n",
    "            .sort_index(axis=1)\n",
    "            .astype(\"Int64\")\n",
    "        )\n",
    "\n",
    "    summary = (\n",
    "        df.groupby(\"experiment_id\")[\"is_correct\"]\n",
    "        .agg([\"sum\", \"count\"])\n",
    "        .assign(\n",
    "            label=lambda s: s.apply(\n",
    "                lambda r: f\"{r['sum']} correct answers of {r['count']} total answers\",\n",
    "                axis=1,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    hit_table[\"Summary\"] = summary.loc[hit_table.index, \"label\"]\n",
    "\n",
    "    overall = summary[[\"sum\", \"count\"]].sum()\n",
    "    hit_table.loc[\"All experiments\", :] = None\n",
    "    hit_table.loc[\"All experiments\", \"Summary\"] = (\n",
    "        f\"{overall['sum']} correct answers of {overall['count']} total answers\"\n",
    "    )\n",
    "\n",
    "    return hit_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8487fddf",
   "metadata": {},
   "source": [
    "The version with \"✅\" and \"❌\" emojis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e55e924",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_miss(df_strictly_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f2edc4",
   "metadata": {},
   "source": [
    "The version with 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b99a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hit_table = hit_miss(df_strictly_numeric, with_emojis=False)\n",
    "#hit_table.to_csv(\"hit_miss_table.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be58c09",
   "metadata": {},
   "source": [
    "What's up with 1-4? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809a0188",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['experiment_id']=='1-4']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcbf502",
   "metadata": {},
   "source": [
    "## 6. Extend evaluation to 3-1, 3-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ca9713",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_precise_answers = df[df['experiment_id'].str.startswith('1-') | \n",
    "                         df['experiment_id'].str.startswith('2-') |\n",
    "                         df['experiment_id'].str.startswith('3-') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6655ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_precise_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecbfdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_miss(df_precise_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c4b9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df01 = hit_miss(df_precise_answers, with_emojis=False)\n",
    "df01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce3cf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df01.to_csv(\"results/hit_miss_table.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de8a833",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eec9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_miss(df_precise_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6830b552",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_precise_answers.query('success == True and normalised_response != correct_answer')[['filename','normalised_response', \n",
    "                                                                                      'correct_answer']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54c0dcb",
   "metadata": {},
   "source": [
    "## 7. Extend evaluation to 5- questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b592bda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_token_as_response(somestring):\n",
    "    if not isinstance(somestring, str):\n",
    "        return None\n",
    "    tokens = somestring.strip().split()\n",
    "    if not tokens:\n",
    "        return None\n",
    "    return tokens[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0669ba71",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['experiment_id'].str.startswith('5-')\n",
    "\n",
    "df.loc[mask, 'normalised_response'] = (\n",
    "    df.loc[mask, 'response']\n",
    "      .apply(get_last_token_as_response)\n",
    "      .str.title()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f231b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['experiment_id'].str.startswith('5-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36944377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8994c022",
   "metadata": {},
   "outputs": [],
   "source": [
    "## hardcoded fix for now\n",
    "mask = (df[\"normalised_response\"] == \"Prinz\") & (df[\"experiment_id\"] != \"5-3\")\n",
    "df.loc[mask, 'correct_answer'] = 'Prinz'\n",
    "\n",
    "mask = (df['normalised_response']=='Der_Prinz') & (df[\"experiment_id\"] != \"5-3\")\n",
    "df.loc[mask, 'correct_answer'] = 'Der_Prinz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84d0e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['experiment_id'].str.startswith('5-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47c7ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"results/compiled_responses.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d003763",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_precise_answers = df[df['experiment_id'].str.startswith('1-') | \n",
    "                         df['experiment_id'].str.startswith('2-') |\n",
    "                         df['experiment_id'].str.startswith('3-') |\n",
    "                         df['experiment_id'].str.startswith('5-')\n",
    "                         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b74727",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_precise_answers = df_precise_answers.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b09659",
   "metadata": {},
   "outputs": [],
   "source": [
    "## how many questions do we cover here? should be 12\n",
    "df_precise_answers['experiment_id'].unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7ef4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_non_open = df_precise_answers.shape[0]\n",
    "total_non_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800538ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_non_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3ab9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_open_success = df_precise_answers['success'].sum()\n",
    "non_open_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f72f15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_open_tool_chains = df_precise_answers[df_precise_answers['tool_chain'].str.len()>0].shape[0]\n",
    "non_open_tool_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5446cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_open_suc_valid = df_precise_answers[(df_precise_answers['valid']!=False) \n",
    "                                          & (df_precise_answers['success']==True)].shape[0]\n",
    "non_open_suc_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac4537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_precise_answers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70b5cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## basic comparison\n",
    "df_precise_answers['is_correct_raw'] = df_precise_answers['response'].astype(str) == df_precise_answers['correct_answer'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4beb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_open_correct_raw = df_precise_answers['is_correct_raw'].sum()\n",
    "non_open_correct_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6212ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct ones\n",
    "df_precise_answers[df_precise_answers['is_correct_raw']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ce0064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrong ones\n",
    "df_precise_answers[~df_precise_answers['is_correct_raw'] & df_precise_answers['success']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91b31ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_norm = df_precise_answers['normalised_response'].astype(str) == df_precise_answers['correct_answer'].astype(str)\n",
    "df_precise_answers['is_correct_norm'] = check_norm\n",
    "non_open_correct_norm = df_precise_answers['is_correct_norm'].sum()\n",
    "non_open_correct_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de6d02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mismatch of the normalised answer with the correct on (so, REALLY wrong)\n",
    "df_precise_answers[~df_precise_answers['is_correct_norm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff16ade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(\n",
    "    number=[total_non_open, non_open_success, \n",
    "            non_open_tool_chains, non_open_suc_valid, \n",
    "            non_open_correct_raw, non_open_correct_norm\n",
    "            ],\n",
    "    stage=[\"Total attempts (non-open Q)\", \"Total success (got response)\", \n",
    "           \"Total Tool Chain Uses\", \"Valid Responses\",\n",
    "           \"Correct answers (direct match)\", \"Correct answers (normalised match)\"\n",
    "           ])\n",
    "\n",
    "# color_discrete_map={\n",
    "#         \"Total attempts\": \"#636EFA\",\n",
    "#         \"Total success (got response)\": \"#00CC96\",\n",
    "#         \"Total Tool Chain Uses\": \"#AB63FA\",\n",
    "#         \"Valid Responses (or open questions)\": \"#FFA15A\"\n",
    "#     }\n",
    "\n",
    "fig = px.funnel(data, x='number', y='stage', title=model.title(), \n",
    "                #color=\"stage\", \n",
    "                #color_discrete_map=color_discrete_map\n",
    "                )\n",
    "fig.update_layout(title_font_size=14, title_x=0.5)  # optional tweaks\n",
    "fig.write_image(f\"results/{model}_results_funnel.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a67cf6",
   "metadata": {},
   "source": [
    "## 8. Add toolchain evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175e639b",
   "metadata": {},
   "source": [
    "Get toolchain validation data into a separate df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee206de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the uploaded files\n",
    "path = f\"results_validated/{model}/*.json\" \n",
    "\n",
    "rows = []\n",
    "\n",
    "for file in glob.glob(path):\n",
    "    with open(file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    filename = os.path.basename(file)\n",
    "    \n",
    "    # Experiment ID is always the first part before the first \"_\"\n",
    "    experiment_id = filename.split(\"_\")[0]  # e.g. \"1-1\"\n",
    "\n",
    "    # Run ID is always the first part before the first \"_\"\n",
    "    run_id = filename.split(\"_validated\")[0]  # e.g. \"1-1_17\"\n",
    "\n",
    "    # Extract the `response` field (if missing, set to None)\n",
    "    response = data.get(\"response\", None)\n",
    "    tool_chain = data.get(\"tool_chain\", None)\n",
    "    success = data.get(\"success\", False)\n",
    "    valid = data.get(\"valid\", False)\n",
    "    absurd_tool_ratio = data.get(\"absurd_tool_ratio\", None)\n",
    "    tool_path_length_difference = data.get(\"tool_path_length_difference\", None)\n",
    "    tool_error_rate = data.get(\"tool_error_rate\", None)\n",
    "    overall_error_rate = tool_error_rate.get(\"overall_error_rate\")\n",
    "\n",
    "    rows.append({\n",
    "        \"filename\": filename,\n",
    "        \"experiment_id\": experiment_id,\n",
    "        \"run_id\": run_id,\n",
    "        \"absurd_tool_ratio\": absurd_tool_ratio,\n",
    "        \"overall_error_rate\": overall_error_rate,\n",
    "        \"tool_path_length_difference\": tool_path_length_difference,\n",
    "        \"success\": success,\n",
    "        #\"response\": response,\n",
    "        \"valid\": valid,\n",
    "        \"tool_chain\": tool_chain,\n",
    "    })\n",
    "\n",
    "df_tool_chains = pd.DataFrame(rows)\n",
    "df_tool_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a72b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tool_chains['absurd_tool_ratio'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b6e8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tool_chains['success'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65889b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tool_chains['absurd_tool_ratio'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d26018",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tool_chains['overall_error_rate'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2350cf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tool_chains['overall_error_rate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948b7b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tool_chains['tool_path_length_difference'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a5a07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tool_chains['tool_path_length_difference'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414b2c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tool_chains['tool_path_length_difference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0629e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tool_chains.groupby('experiment_id')['overall_error_rate'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39c3a88",
   "metadata": {},
   "source": [
    "Combine with correctness info and analyse correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d48014",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_precise_answers['run_id'] = df_precise_answers['filename'].apply(lambda x: x.split(\"_extracted\")[0])\n",
    "df_precise_answers['run_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09493eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_merge = df_precise_answers[['run_id', 'is_correct_norm', 'is_correct_raw']]\n",
    "to_merge = to_merge.rename(columns={\"is_correct_raw\": \"is_correct_raw\"})\n",
    "to_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe16b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = (\n",
    "    df_tool_chains.merge(\n",
    "        to_merge,  \n",
    "        on=\"run_id\",\n",
    "        how=\"left\",  \n",
    "        validate=\"one_to_one\"\n",
    "    )\n",
    ")\n",
    "\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38effac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = merged[\"overall_error_rate\"].corr(merged[\"is_correct_norm\"])\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8311fafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = merged[\"tool_path_length_difference\"].corr(merged[\"is_correct_norm\"])\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4ada7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = merged[\"absurd_tool_ratio\"].corr(merged[\"is_correct_norm\"])\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a4cd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_precise_answers.groupby('experiment_id')['is_correct_norm'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd5819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = merged[\"overall_error_rate\"].corr(merged[\"tool_path_length_difference\"])\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d94df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[(merged['overall_error_rate'] == 0) & (merged['is_correct_norm'] != True)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4181e202",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[(merged['overall_error_rate'] == 0) & (merged['is_correct_norm'] == True)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e524ad42",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[(merged['overall_error_rate'] == 0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfdb7dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
