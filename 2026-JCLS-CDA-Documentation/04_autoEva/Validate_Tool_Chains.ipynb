{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbc91941-c501-403c-a0c5-add02e415058",
   "metadata": {},
   "source": [
    "# Evaluate tool chains\n",
    "* length for estimating complexity\n",
    "* check tool against possible list of tools (absurdity of approach) \n",
    "* Word Error Rate: Substitutions, Deletion, Insertions\n",
    "  * (S + D + I) / N_reference\n",
    "  * if a tool is added, but all other are correct it is the same as if one tool was wrong, but the length is the same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f020523-501f-4482-ad81-5476ea9c7fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/analyticsinmotion/werx\n",
    "import werx\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020064f8-f7ce-4005-8047-39bd6cc37a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test word error rate\n",
    "hypothesis = [\"get_corpora\", \"get_plays_in_corpus_by_title_helper\", \"get_play_characters\", \"some_other\"]\n",
    "reference = [\"get_corpora\", \"get_plays_in_corpus_by_title_helper\", \"get_play_characters\"]\n",
    "reference_multiple = [[\"get_corpora\", \"get_plays_in_corpus_by_title_helper\", \"get_play_characters\"],\n",
    "             [\"get_corpora\", \"get_plays_in_corpus_by_title_helper\", \"get_play_characters\", \"some_other\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0974fbcc-cd14-48f3-9b1a-38348a0e3b8d",
   "metadata": {},
   "source": [
    "## Read data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7675be03-1e67-4bd5-a892-91de1b8cc18d",
   "metadata": {},
   "source": [
    "#### Manually created tables to compare the LLM's answer to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c95df4-105b-4fa7-a18b-fb4a7f433f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible tools\n",
    "prossible_tool_table_path = \"preliminary_work/DraCor MCP Tools - Tabellenblatt1.csv\"\n",
    "possible_tools_df = pd.read_csv(prossible_tool_table_path)\n",
    "\n",
    "# optimal length \n",
    "optimal_lengths_json_path = Path(\"preliminary_work/expected_tool_chains_light.json\")\n",
    "with optimal_lengths_json_path.open('r') as optimal_length_json:\n",
    "    optimal_lengths = json.load(optimal_length_json)\n",
    "\n",
    "# baseline chain\n",
    "base_toolchain_json_path = Path(\"preliminary_work/mcp-evaluation-baseline-tool-chains.json\")\n",
    "with base_toolchain_json_path.open('r') as base_toolchain_json:\n",
    "    baseline_tool_chain_raw = json.load(base_toolchain_json)\n",
    "    baseline_tool_chain = {entry[\"ID\"]: entry[\"baseline_tool_chains\"] for entry in baseline_tool_chain_raw}\n",
    "    #baseline_tool_chain_df = pd.DataFrame(baseline_tool_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48a7483-977d-4518-b5b6-ef7c49e5d15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_tools_df = possible_tools_df.rename(columns={\"Tool/Question\": \"tool\"})\n",
    "possible_tools_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8124d1d5-7cc6-454a-ac3e-eccbbe4ac67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_starter(tool_path):\n",
    "    tool_path = tool_path.split(\":\")\n",
    "    return tool_path[1]\n",
    "\n",
    "    \n",
    "possible_tools_df[\"tool\"] = possible_tools_df[\"tool\"].apply(lambda x: strip_starter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aba1c6-c7e7-49be-ba51-d07354c521f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_tools_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb17a542-3351-4cd3-a9e2-496e7c838e0b",
   "metadata": {},
   "source": [
    "Transpose length dict to df with question ids as column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab84d68c-4411-4f40-ab4b-71e2f22fc330",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_lengths_df = pd.DataFrame(optimal_lengths).set_index(\"ID\").transpose()\n",
    "optimal_lengths_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d77c39-1bf0-4742-bdb0-5e3d0ee59d68",
   "metadata": {},
   "source": [
    "#### LLM's answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396e3293-ef10-4af0-b30f-3a6749669274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory to answers\n",
    "sonnet_path = Path(\"results/sonnet-4/extracted/\")\n",
    "haiku_path = Path(\"results/haiku-4-5/extracted/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a14e45-4b68-4ef6-a234-ff95a9c4c411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as the results also include metadata to the question and the run, we don't need the file name for mapping\n",
    "def read_results(result_dir:Path, runs_to_analyse:list[int]) -> list[dict]:\n",
    "    results = []\n",
    "    for filepath in result_dir.iterdir():\n",
    "        run = int(filepath.name.split(\"_\")[1])\n",
    "        if run in runs_to_analyse:\n",
    "            with filepath.open('r') as json_in:\n",
    "                result = json.load(json_in)\n",
    "                if result[\"success\"]:\n",
    "                    results.append(result)    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265524bb-7a12-4999-89b8-3244d0dd54b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_to_analyse_sonnet = list(range(11,21))\n",
    "runs_to_analyse_haiku = list(range(1,11))\n",
    "\n",
    "sonnet_runs = read_results(sonnet_path, runs_to_analyse_sonnet)\n",
    "haiku_runs = read_results(haiku_path, runs_to_analyse_haiku)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d9e7cc-5455-4902-8081-5b5450e2eecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sonnet_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6e8813-b398-4cf0-a165-cfdf53657fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(haiku_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8566420-a74c-4bf2-b05a-5b7a2b995209",
   "metadata": {},
   "outputs": [],
   "source": [
    "sonnet_runs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7d2d45-9985-49c6-8bc1-0a935010e136",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9620e6d9-a010-4d09-a3ee-7936bc0346bc",
   "metadata": {},
   "source": [
    "### Length Difference\n",
    "* put this into relation to tool length of reference? (if the reference chain is longer, more difference in length weigh lower?)\n",
    "* what if the hypothesis chain is shorter? (e.g. reference is \"get corpus name\" & \"get corpus\", hypothesis is \"get corpus\") --> at the moment distance = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c30b39-d1df-4fab-9f4e-567b9bad1b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate with optimal tool path\n",
    "length_difference = abs(len(hypothesis) - len(reference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc9339a-5ea6-41d7-9be9-71c6eb3e3f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate with manually set optimal length\n",
    "def calculate_length_difference(hypothesis_length, reference_length):\n",
    "    return abs(hypothesis_length - reference_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7018a007-bf45-4c67-881d-98a3d5659dab",
   "metadata": {},
   "source": [
    "### Ratio of absurd tools used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda07f5a-952e-48ae-8b5b-cdbc4604bec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_tools = set([\"get_corpora\", \"get_plays_in_corpus_by_title_helper\", \"get_play_characters\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cc7da0-88a6-464a-b405-3a165e5ba85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_set = set(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d4f751-604e-44bf-ac4d-234bbc4a16ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_absurd_tool_ratio(hypothesis_set, possible_tools):\n",
    "    absurd_tools = hypothesis_set.difference(possible_tools)\n",
    "    absurdity_rate = len(absurd_tools) / len(hypothesis_set)\n",
    "    return absurdity_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a75dd5b-aeea-4184-a448-1fc60323a12a",
   "metadata": {},
   "source": [
    "### WER \n",
    "* add function to get optimal tool chain from df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8534b49e-72bd-4820-9c97-e06e83f88692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wer_info(hypothesis_tools: list[str], reference_tools: list[list[str]]):\n",
    "    reference_tools_str = [\" \".join(reference) for reference in reference_tools]\n",
    "    hypothesis_str = \" \".join(hypothesis_tools)\n",
    "    best_score = 10000 # some high number, so that the first calculation will be below (is not between 0 and 1)\n",
    "    for reference_str in reference_tools_str:\n",
    "        error_rate = werx.wer(reference_str, hypothesis_str)\n",
    "        if error_rate < best_score:\n",
    "            wer = {}\n",
    "            best_score = error_rate\n",
    "            results = werx.analysis(reference_str, hypothesis_str)\n",
    "            result = results[0]\n",
    "            \n",
    "            wer[\"overall_error_rate\"] = error_rate\n",
    "            wer[\"insertions\"] = result.inserted_words\n",
    "            wer[\"deletions\"] = result.deleted_words\n",
    "            wer[\"substitutions\"] = result.substituted_words\n",
    "    return wer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7884bde-1d21-491f-b8bf-964e21b60fde",
   "metadata": {},
   "source": [
    "### Calculate Validation Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e227a8b-ba7a-43ca-9932-9c883352bb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_possible_tools(possible_tools_df, question_id):\n",
    "    return set(list(possible_tools_df[possible_tools_df[question_id]>0][\"tool\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5fed57-b60f-4b3c-a981-0c703fa303d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_length(optimal_lengths_df, question_id):\n",
    "    return optimal_lengths_df[question_id][\"number_of_tools_expected\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f0f9ba-76e7-4cf0-b90f-55d469ccdb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_tool_chains(results, possible_tools_df, optimal_lengths_df, baseline_tool_chains):\n",
    "    for result in results:\n",
    "        question_id = result[\"id\"]\n",
    "        tools = result[\"tool_chain\"]\n",
    "        \n",
    "        # length difference\n",
    "        optimal_length = get_optimal_length(optimal_lengths_df, question_id) \n",
    "        result[\"tool_path_length_difference\"] = calculate_length_difference(len(tools), optimal_length)\n",
    "\n",
    "        # absurd tools \n",
    "        possible_tools = get_possible_tools(possible_tools_df, question_id)\n",
    "        result[\"absurd_tool_ratio\"] = get_absurd_tool_ratio(set(tools), possible_tools)\n",
    "\n",
    "        # tool path error rate aka WER\n",
    "        # todo: reference must be list of lists\n",
    "        # get optimal tool chain for question_id\n",
    "        result[\"tool_error_rate\"] = get_wer_info(tools, baseline_tool_chains[question_id])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d48c40-4799-4b12-9dda-59979f6ee79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sonnet_evaluated = validate_tool_chains(sonnet_runs, possible_tools_df, optimal_lengths_df, baseline_tool_chain)\n",
    "haiku_evaluated = validate_tool_chains(haiku_runs, possible_tools_df, optimal_lengths_df, baseline_tool_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dbc6c2-4643-46f2-9ba6-d55d539d9975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# haiku  tool path investigation\n",
    "\n",
    "question_id = \"3-2\"\n",
    "\n",
    "for i, entry in enumerate(sonnet_evaluated):\n",
    "    if entry['id'] == question_id:\n",
    "        print(entry['id'])\n",
    "        print(f\"{i}: Tools chain: {entry['tool_chain']}\")\n",
    "        print(entry['tool_path_length_difference'])\n",
    "        print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7b6d7f-b269-4b86-8856-6f9436b9c62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haiku tool chain analysis\n",
    "question_id = \"3-2\"\n",
    "\n",
    "for i, entry in enumerate(haiku_evaluated):\n",
    "    if entry['id'] == question_id:\n",
    "        print(f\"{i}: Tools chain: {entry['tool_chain']}\")\n",
    "        print(entry['tool_error_rate'])\n",
    "        print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5933a8-d426-451a-ac35-26bde173bf04",
   "metadata": {},
   "source": [
    "## Write validation results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bc0bde-a5fa-441f-aeb2-1286563ec732",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"results_validated/\")\n",
    "output_dir_sonnet = output_dir / \"sonnet-4\"\n",
    "output_dir_haiku = output_dir / \"haiku-4-5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6931ba-312e-4d60-b338-bf8425dba9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_validated_results(result_path:Path, validated_runs:list[dict]):\n",
    "    if not result_path.exists():\n",
    "        result_path.mkdir()\n",
    "    for entry in validated_runs:\n",
    "        filename = result_path / f\"{entry['id']}_{entry['run']}_validated-tools.json\"\n",
    "        with filename.open('w') as file_out:\n",
    "            json.dump(entry, file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dc2490-abfa-4d25-a63d-6e0e75399421",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_validated_results(output_dir_sonnet, sonnet_evaluated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c1171c-9970-471c-9f80-9e367f39cb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_validated_results(output_dir_haiku, haiku_evaluated)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
