{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c613106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from pydracor import DraCorAPI\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b28c833",
   "metadata": {},
   "source": [
    "## 1. Loading experiments results from JSON files to a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491d4476",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_PREFIXES = [\n",
    "    \"1-1\",\n",
    "    \"1-2\",\n",
    "    \"1-3\",\n",
    "    \"1-4\",\n",
    "    \"1-5\",\n",
    "    \"3-1\",\n",
    "    \"4-1\",\n",
    "    \"4-2\",\n",
    "    \"4-3\",\n",
    "    \"4-4\",\n",
    "    \"5-1\",\n",
    "    \"5-2\",\n",
    "    \"5-3\",\n",
    "    \"5-4\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f6b4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = 'haiku-4-5' #choose this for haiku-4-5\n",
    "model = 'sonnet-4' # choose this for sonnet-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c873674b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the uploaded files\n",
    "path = f\"../results/{model}/extracted/*.json\" \n",
    "\n",
    "rows = []\n",
    "\n",
    "for file in glob.glob(path):\n",
    "    with open(file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    filename = os.path.basename(file)\n",
    "    \n",
    "    # Experiment ID is always the first part before the first \"_\"\n",
    "    experiment_id = filename.split(\"_\")[0]  # e.g. \"1-1\"\n",
    "\n",
    "    # Extract the `response` field (if missing, set to None)\n",
    "    response = data.get(\"response\", None)\n",
    "    tool_chain = data.get(\"tool_chain\", None)\n",
    "    success = data.get(\"success\", False)\n",
    "    valid = data.get(\"valid\", False)\n",
    "\n",
    "    rows.append({\n",
    "        \"filename\": filename,\n",
    "        \"experiment_id\": experiment_id,\n",
    "        \"success\": success,\n",
    "        \"response\": response,\n",
    "        \"valid\": valid,\n",
    "        \"tool_chain\": tool_chain,\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d2d7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['experiment_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2f5547",
   "metadata": {},
   "source": [
    "### Basic stats on how many successful / failed runs \n",
    "\n",
    "(testing for 'request failure', step 1 in Henny's diagram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0898533",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_attempts = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbae11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['success'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a75566",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_suscesses = df['success'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af351941",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['tool_chain'].str.len()>0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f2ea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tool_chains = df[df['tool_chain'].str.len()>0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec8d650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid True or null\n",
    "df[df['valid']!=False].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a9ac7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_invalid = df[(df['valid']!=False) & (df['success']==True)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8803d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## no color settings\n",
    "data = dict(\n",
    "    number=[total_attempts, total_suscesses, total_tool_chains, not_invalid],\n",
    "    stage=[\"Total attempts\", \"Total success (got response)\", \"Total Tool Chain Uses\", \"Valid Responses (or open questions)\"])\n",
    "\n",
    "fig = px.funnel(data, x='number', y='stage', title=model.title())\n",
    "fig.update_layout(title_font_size=14, title_x=0.5)  # optional tweaks\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ee5add",
   "metadata": {},
   "outputs": [],
   "source": [
    "## no color settings\n",
    "data = dict(\n",
    "    number=[total_attempts, total_suscesses, total_tool_chains, not_invalid],\n",
    "    stage=[\"Total attempts\", \"Total success (got response)\", \"Total Tool Chain Uses\", \"Valid Responses (or open questions)\"])\n",
    "\n",
    "fig = px.funnel(data, x='number', y='stage', title=model.title(),\n",
    "                color_discrete_sequence=[\"#1f2448\"])\n",
    "fig.update_layout(title_font_size=14, title_x=0.5)  # optional tweaks\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c596155c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with color settings\n",
    "# data = dict(\n",
    "#     number=[total_attempts, total_suscesses, total_tool_chains, not_invalid],\n",
    "#     stage=[\"Total attempts\", \"Total success (got response)\", \"Total Tool Chain Uses\", \"Valid Responses (or open questions)\"])\n",
    "\n",
    "# color_discrete_map={\n",
    "        \n",
    "#          \"Total attempts\": \"#1f2448\",\n",
    "#          \"Total success (got response)\": \"#fc9432\",\n",
    "#          \"Total Tool Chain Uses\": \"#1f2448\",\n",
    "#          \"Valid Responses (or open questions)\": \"#008a0e\"\n",
    "         \n",
    "#      }\n",
    "\n",
    "# fig = px.funnel(data, x='number', y='stage', title=model.title(), \n",
    "#                 color=\"stage\", \n",
    "#                 color_discrete_map=color_discrete_map\n",
    "#                 )\n",
    "# fig.update_layout(title_font_size=14, title_x=0.5)  # optional tweaks\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933b953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['success']==True]['valid'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5284cf80",
   "metadata": {},
   "source": [
    "## 2. Post-processing LLM responses for better automatic evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d494afbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_last_number(s):\n",
    "    if s is None:\n",
    "        return None\n",
    "    # find all groups of digits\n",
    "    nums = re.findall(r\"\\d+\", str(s))\n",
    "    if not nums:\n",
    "        return None\n",
    "    return int(nums[-1])  # take the last one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f00136",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"numeric_response\"] = df[\"response\"].apply(extract_last_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3225ea3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17da9cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1605ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_numbers(s):\n",
    "    if s is None:\n",
    "        return []\n",
    "    # find all groups of digits\n",
    "    nums = re.findall(r\"\\d+\", str(s))\n",
    "    return [int(n) for n in nums]  # convert to ints\n",
    "\n",
    "df[\"all_numbers\"] = df[\"response\"].apply(extract_all_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4b5e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['experiment_id']=='1-5'][['filename', 'response', 'numeric_response', 'all_numbers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413d0b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['experiment_id']=='1-5'][['response', 'numeric_response', 'all_numbers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5d659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28fa2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats = (\n",
    "#     df_filtered.groupby(\"experiment_id\")[\"numeric_response\"]\n",
    "#       .agg([\"count\", \"mean\", \"std\", \"var\", \"min\", \"max\"])\n",
    "# )\n",
    "\n",
    "# # add range as max-min\n",
    "# stats[\"range\"] = stats[\"max\"] - stats[\"min\"]\n",
    "\n",
    "# stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a069896",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"experiment_id\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2ad75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"experiment_id\")[\"numeric_response\"].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb23c2f9",
   "metadata": {},
   "source": [
    "### Normalise responses to select-the-corpus questions (3-1, 3-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a4615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalised response will contain the same as numeric_response for numeric questions \n",
    "# but also corpus slugs for 'which corpus' questions\n",
    "df['normalised_response'] = df['numeric_response'].astype('string')\n",
    "df['normalised_response'] = df['normalised_response'].str.replace('.0$', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0912e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['normalised_response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1b1c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should all be replaced by the corpus slugs \n",
    "df[df['experiment_id'].isin(['3-1', '3-2'])]['normalised_response']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba299d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "crpra = DraCorAPI().get_corpora()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b69b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "slugs = [corpus.name for corpus in crpra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4f1648",
   "metadata": {},
   "outputs": [],
   "source": [
    "_pattern = re.compile(r'\\b(?:' + '|'.join(slugs) + r')\\b', flags=re.IGNORECASE)\n",
    "\n",
    "def find_last_corpus_slug(text: str) -> str | None:\n",
    "    \"\"\"Return the last DraCor slug mentioned as a whole word, or None.\"\"\"\n",
    "    last = None\n",
    "    for match in _pattern.finditer(text):\n",
    "        last = match.group(0).lower()  # normalize to lowercase slug\n",
    "    return last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba38f0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['experiment_id'].isin(['3-1', '3-2'])\n",
    "df.loc[mask, 'normalised_response'] = df.loc[mask, 'response'].apply(find_last_corpus_slug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cc0a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['experiment_id'].isin(['3-1', '3-2'])][['success','response','normalised_response']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324e339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['experiment_id'].isin(['3-1', '3-2']) & df['success']==True)][['experiment_id','success','response','normalised_response']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4369430d",
   "metadata": {},
   "source": [
    "## 3. Loading manually-defined correct responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66f9e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = pd.read_csv(\"../curated_data/autoEva_correct-answers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b00eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c340dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa06998",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_dict = dict(zip(correct[\"ID\"], correct[\"Correct Answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63afc48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['correct_answer'] = df['experiment_id'].map(correct_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab28957",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3bc8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[['experiment_id', 'numeric_response', 'correct_answer']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e745c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_strictly_numeric = df[df['experiment_id'].str.startswith('1-') | \n",
    "                         df['experiment_id'].str.startswith('2-') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a42d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_strictly_numeric.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5499cc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_strictly_numeric[['experiment_id', 'numeric_response', 'correct_answer']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1064e725",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_strictly_numeric[df_strictly_numeric['experiment_id'] == '1-3']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a1cacb",
   "metadata": {},
   "source": [
    "## 4. Evaluating correctness of the LLM response (hit & miss table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f05794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_miss(df, with_emojis=True):\n",
    "    df = df.copy()\n",
    "    df[\"is_correct\"] = df[\"normalised_response\"] == df[\"correct_answer\"]\n",
    "    df[\"iteration\"] = df.groupby(\"experiment_id\").cumcount() + 1\n",
    "    df[\"question_id\"] = df[\"experiment_id\"]\n",
    "\n",
    "    if with_emojis:\n",
    "        df[\"emoji\"] = df[\"is_correct\"].map({1: \"✅\", 0: \"❌\"})\n",
    "        hit_table = (\n",
    "            df.pivot(index=\"question_id\", columns=\"iteration\", values=\"emoji\")\n",
    "            .sort_index()\n",
    "            .sort_index(axis=1)\n",
    "        )\n",
    "    else:\n",
    "        hit_table = (\n",
    "            df.pivot(index=\"question_id\", columns=\"iteration\", values=\"is_correct\")\n",
    "            .sort_index()\n",
    "            .sort_index(axis=1)\n",
    "            .astype(\"Int64\")\n",
    "        )\n",
    "\n",
    "    summary = (\n",
    "        df.groupby(\"question_id\")[\"is_correct\"]\n",
    "        .agg([\"sum\", \"count\"])\n",
    "        .assign(\n",
    "            label=lambda s: s.apply(\n",
    "                lambda r: f\"{r['sum']} correct answers of {r['count']} total answers\",\n",
    "                axis=1,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    hit_table[\"Summary\"] = summary.loc[hit_table.index, \"label\"]\n",
    "\n",
    "    overall = summary[[\"sum\", \"count\"]].sum()\n",
    "    hit_table.loc[\"All experiments\", :] = None\n",
    "    hit_table.loc[\"All experiments\", \"Summary\"] = (\n",
    "        f\"{overall['sum']} correct answers of {overall['count']} total answers\"\n",
    "    )\n",
    "\n",
    "    return hit_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3ca79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Revised hit_miss function to handle multiple acceptable answers\n",
    "\n",
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "def hit_miss(df, with_emojis=True):\n",
    "    df = df.copy()\n",
    "\n",
    "    def _to_answer_set(x):\n",
    "        if pd.isna(x):\n",
    "            return set()\n",
    "\n",
    "        if isinstance(x, (list, tuple, set)):\n",
    "            return {str(v).strip() for v in x if not pd.isna(v)}\n",
    "\n",
    "        if isinstance(x, str):\n",
    "            s = x.strip()\n",
    "            if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "                try:\n",
    "                    parsed = ast.literal_eval(s)\n",
    "                    if isinstance(parsed, (list, tuple, set)):\n",
    "                        return {str(v).strip() for v in parsed if not pd.isna(v)}\n",
    "                except (ValueError, SyntaxError):\n",
    "                    pass\n",
    "            return {s}\n",
    "\n",
    "        return {str(x).strip()}\n",
    "\n",
    "    # IDs\n",
    "    df[\"question_id\"] = df[\"experiment_id\"]\n",
    "\n",
    "    # Define what counts as an \"answered\" run:\n",
    "    # - if a boolean 'success' exists, use it\n",
    "    # - else infer from normalised_response being non-missing\n",
    "    if \"success\" in df.columns:\n",
    "        df[\"answered\"] = df[\"success\"].astype(bool)\n",
    "    else:\n",
    "        df[\"answered\"] = ~pd.isna(df[\"normalised_response\"])\n",
    "\n",
    "    # Precompute acceptable answers per question\n",
    "    acceptable = (\n",
    "        df.groupby(\"question_id\")[\"correct_answer\"]\n",
    "          .first()\n",
    "          .apply(_to_answer_set)\n",
    "          .to_dict()\n",
    "    )\n",
    "\n",
    "    def _is_correct_row(r):\n",
    "        if not r[\"answered\"]:\n",
    "            return pd.NA  # <-- key change: non-answer stays NA (blank), not False\n",
    "        ans = r[\"normalised_response\"]\n",
    "        return str(ans).strip() in acceptable.get(r[\"question_id\"], set())\n",
    "\n",
    "    df[\"is_correct\"] = df.apply(_is_correct_row, axis=1)\n",
    "\n",
    "    # Iteration numbering stays based on experiment_id (same as before)\n",
    "    df[\"iteration\"] = df.groupby(\"experiment_id\").cumcount() + 1\n",
    "\n",
    "    # Build table\n",
    "    if with_emojis:\n",
    "        df[\"emoji\"] = df[\"is_correct\"].map({True: \"✅\", False: \"❌\"})\n",
    "        hit_table = (\n",
    "            df.pivot(index=\"question_id\", columns=\"iteration\", values=\"emoji\")\n",
    "              .sort_index()\n",
    "              .sort_index(axis=1)\n",
    "        )\n",
    "    else:\n",
    "        hit_table = (\n",
    "            df.pivot(index=\"question_id\", columns=\"iteration\", values=\"is_correct\")\n",
    "              .sort_index()\n",
    "              .sort_index(axis=1)\n",
    "              .astype(\"Int64\")  # keeps <NA> as blank in CSV\n",
    "        )\n",
    "\n",
    "    # Summary: denominator should be ANSWERED runs only (i.e., is_correct not NA)\n",
    "    summary = (\n",
    "        df.groupby(\"question_id\")[\"is_correct\"]\n",
    "          .agg(\n",
    "              n_correct=lambda s: (s == True).sum(),\n",
    "              n_answered=lambda s: s.notna().sum(),\n",
    "          )\n",
    "          .assign(\n",
    "              label=lambda s: s.apply(\n",
    "                  lambda r: f\"{int(r['n_correct'])} correct answers of {int(r['n_answered'])} total answers\",\n",
    "                  axis=1,\n",
    "              )\n",
    "          )\n",
    "    )\n",
    "\n",
    "    hit_table[\"Summary\"] = summary.loc[hit_table.index, \"label\"]\n",
    "\n",
    "    # Overall: same denominator logic\n",
    "    overall_correct = int(summary[\"n_correct\"].sum())\n",
    "    overall_answered = int(summary[\"n_answered\"].sum())\n",
    "\n",
    "    hit_table.loc[\"All experiments\", :] = None\n",
    "    hit_table.loc[\"All experiments\", \"Summary\"] = (\n",
    "        f\"{overall_correct} correct answers of {overall_answered} total answers\"\n",
    "    )\n",
    "\n",
    "    return hit_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8487fddf",
   "metadata": {},
   "source": [
    "The version with \"✅\" and \"❌\" emojis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e55e924",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_miss(df_strictly_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f2edc4",
   "metadata": {},
   "source": [
    "The version with 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b99a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hit_table = hit_miss(df_strictly_numeric, with_emojis=False)\n",
    "#hit_table.to_csv(\"hit_miss_table.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be58c09",
   "metadata": {},
   "source": [
    "What's up with 1-4? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809a0188",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['experiment_id']=='1-4']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcbf502",
   "metadata": {},
   "source": [
    "## 6. Extend evaluation to 3-1, 3-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ca9713",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_precise_answers = df[df['experiment_id'].str.startswith('1-') | \n",
    "                         df['experiment_id'].str.startswith('2-') |\n",
    "                         df['experiment_id'].str.startswith('3-') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6655ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_precise_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecbfdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_miss(df_precise_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c4b9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df01 = hit_miss(df_precise_answers, with_emojis=False)\n",
    "df01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce3cf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df01.to_csv(\"results/hit_miss_table.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de8a833",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eec9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_miss(df_precise_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6830b552",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_precise_answers.query('success == True and normalised_response != correct_answer')[['filename','normalised_response', \n",
    "                                                                                      'correct_answer']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54c0dcb",
   "metadata": {},
   "source": [
    "## 7. Extend evaluation to 5- questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b592bda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_token_as_response(somestring):\n",
    "    if not isinstance(somestring, str):\n",
    "        return None\n",
    "    tokens = somestring.strip().split()\n",
    "    if not tokens:\n",
    "        return None\n",
    "    return tokens[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0669ba71",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['experiment_id'].str.startswith('5-')\n",
    "\n",
    "df.loc[mask, 'normalised_response'] = (\n",
    "    df.loc[mask, 'response']\n",
    "      .apply(get_last_token_as_response)\n",
    "      .str.lower()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f231b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['experiment_id'].str.startswith('5-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84d0e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['experiment_id'].str.startswith('5-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe157d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc363989",
   "metadata": {},
   "source": [
    "Output format for saving to csv (put 'response' as the last column because they are very long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdd6852",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['filename', 'experiment_id', 'success', 'valid',\n",
    "       'tool_chain', 'normalised_response', \n",
    "       'correct_answer', 'numeric_response', 'all_numbers', 'response']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47c7ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['filename', 'experiment_id', 'success', 'valid',\n",
    "       'tool_chain', 'normalised_response', \n",
    "       'correct_answer', 'numeric_response', 'all_numbers', 'response']].to_csv(f\"../results_analysed/tables/compiled_responses_{model}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8bc35f",
   "metadata": {},
   "source": [
    "Select only questions with non-open answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d003763",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_precise_answers = df[df['experiment_id'].str.startswith('1-') | \n",
    "                         df['experiment_id'].str.startswith('2-') |\n",
    "                         df['experiment_id'].str.startswith('3-') |\n",
    "                         df['experiment_id'].str.startswith('5-')\n",
    "                         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b74727",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_precise_answers = df_precise_answers.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b09659",
   "metadata": {},
   "outputs": [],
   "source": [
    "## how many questions do we cover here? should be 12\n",
    "df_precise_answers['experiment_id'].unique().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8034f8",
   "metadata": {},
   "source": [
    "### get stats for the funnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea07b494",
   "metadata": {},
   "outputs": [],
   "source": [
    "## to handle answers that have multiple acceptable options\n",
    "def _to_answer_set(x):\n",
    "    if pd.isna(x):\n",
    "        return set()\n",
    "\n",
    "    if isinstance(x, (list, tuple, set)):\n",
    "        return {str(v).strip() for v in x if not pd.isna(v)}\n",
    "\n",
    "    if isinstance(x, str):\n",
    "        s = x.strip()\n",
    "        if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "            try:\n",
    "                parsed = ast.literal_eval(s)\n",
    "                if isinstance(parsed, (list, tuple, set)):\n",
    "                    return {str(v).strip() for v in parsed if not pd.isna(v)}\n",
    "            except (ValueError, SyntaxError):\n",
    "                pass\n",
    "        return {s}\n",
    "\n",
    "    return {str(x).strip()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31721b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build acceptable-answer sets per question\n",
    "answer_sets = (\n",
    "    df_precise_answers\n",
    "        .groupby(\"experiment_id\")[\"correct_answer\"]\n",
    "        .first()\n",
    "        .apply(_to_answer_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7ef4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_non_open = df_precise_answers.shape[0]\n",
    "total_non_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800538ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_non_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3ab9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_open_success = df_precise_answers['success'].sum()\n",
    "non_open_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f72f15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_open_tool_chains = df_precise_answers[df_precise_answers['tool_chain'].str.len()>0].shape[0]\n",
    "non_open_tool_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5446cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_open_suc_valid = df_precise_answers[(df_precise_answers['valid']!=False) \n",
    "                                          & (df_precise_answers['success']==True)].shape[0]\n",
    "non_open_suc_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac4537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_precise_answers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7683c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply membership test\n",
    "df_precise_answers[\"is_correct_raw\"] = df_precise_answers.apply(\n",
    "    lambda r: str(r[\"response\"]).strip().lower()\n",
    "              in answer_sets.get(r[\"experiment_id\"], set()),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70b5cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## basic comparison\n",
    "#df_precise_answers['is_correct_raw'] = df_precise_answers['response'].astype(str) == df_precise_answers['correct_answer'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4beb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_open_correct_raw = df_precise_answers['is_correct_raw'].sum()\n",
    "non_open_correct_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6212ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct ones\n",
    "df_precise_answers[df_precise_answers['is_correct_raw']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ce0064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrong ones\n",
    "df_precise_answers[~df_precise_answers['is_correct_raw'] & df_precise_answers['success']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8745d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrong ones\n",
    "#df_precise_answers[~df_precise_answers['is_correct_raw'] & df_precise_answers['success']==True][['filename','response','normalised_response', 'correct_answer']].to_csv(f\"results/wrong_responses_{model}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a694766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply membership test\n",
    "df_precise_answers[\"is_correct_norm\"] = df_precise_answers.apply(\n",
    "    lambda r: str(r[\"normalised_response\"]).strip().lower()\n",
    "              in answer_sets.get(r[\"experiment_id\"], set()),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91b31ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check_norm = df_precise_answers['normalised_response'].astype(str) == df_precise_answers['correct_answer'].astype(str)\n",
    "#df_precise_answers['is_correct_norm'] = check_norm\n",
    "non_open_correct_norm = df_precise_answers['is_correct_norm'].sum()\n",
    "non_open_correct_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de6d02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mismatch of the normalised answer with the correct on (so, REALLY wrong)\n",
    "df_precise_answers[~df_precise_answers['is_correct_norm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba01192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    "@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap');\n",
    "</style>\n",
    "\"\"\")\n",
    "\n",
    "fig.update_layout(\n",
    "    font=dict(family=\"Inter, sans-serif\", size=12, color=\"#1f2444\")\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff16ade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(\n",
    "    number=[total_non_open, non_open_success, \n",
    "            non_open_tool_chains, non_open_suc_valid, \n",
    "            non_open_correct_raw, non_open_correct_norm\n",
    "            ],\n",
    "    stage=[\"Total attempts (non-open questions)\", \"Total success (got response)\", \n",
    "           \"Total Tool Chain Uses\", \"Valid Responses\",\n",
    "           \"Correct answers (direct match)\", \"Correct answers (direct + normalised match)\"\n",
    "           ])\n",
    "\n",
    "fig = px.funnel(data, x='number', y='stage', title=model.title(),\n",
    "                color_discrete_sequence=[\"#1f2448\"])\n",
    "\n",
    "fig.update_layout(title_font_size=14, title_x=0.5)  # optional tweaks\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    font=dict(family=\"Inter, sans-serif\", size=14, color=\"#1f2444\")\n",
    ")\n",
    "\n",
    "fig.write_image(f\"../results_analysed/images/{model}_results_funnel.png\", scale=300/96)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a67cf6",
   "metadata": {},
   "source": [
    "## 8. Add toolchain evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175e639b",
   "metadata": {},
   "source": [
    "Get toolchain validation data into a separate df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee206de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the uploaded files\n",
    "path = f\"../results_validated/{model}/*.json\" \n",
    "\n",
    "rows = []\n",
    "\n",
    "for file in glob.glob(path):\n",
    "    with open(file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    filename = os.path.basename(file)\n",
    "    \n",
    "    # Experiment ID is always the first part before the first \"_\"\n",
    "    experiment_id = filename.split(\"_\")[0]  # e.g. \"1-1\"\n",
    "\n",
    "    # Run ID is always the first part before the first \"_\"\n",
    "    run_id = filename.split(\"_validated\")[0]  # e.g. \"1-1_17\"\n",
    "\n",
    "    # Extract the `response` field (if missing, set to None)\n",
    "    response = data.get(\"response\", None)\n",
    "    tool_chain = data.get(\"tool_chain\", None)\n",
    "    success = data.get(\"success\", False)\n",
    "    valid = data.get(\"valid\", False)\n",
    "    absurd_tool_ratio = data.get(\"absurd_tool_ratio\", None)\n",
    "    tool_path_length_difference = data.get(\"tool_path_length_difference\", None)\n",
    "    tool_error_rate = data.get(\"tool_error_rate\", None)\n",
    "    overall_error_rate = tool_error_rate.get(\"overall_error_rate\")\n",
    "\n",
    "    rows.append({\n",
    "        \"filename\": filename,\n",
    "        \"experiment_id\": experiment_id,\n",
    "        \"run_id\": run_id,\n",
    "        \"absurd_tool_ratio\": absurd_tool_ratio,\n",
    "        \"overall_error_rate\": overall_error_rate,\n",
    "        \"tool_path_length_difference\": tool_path_length_difference,\n",
    "        \"success\": success,\n",
    "        #\"response\": response,\n",
    "        \"valid\": valid,\n",
    "        \"tool_chain\": tool_chain,\n",
    "    })\n",
    "\n",
    "df_tool_chains = pd.DataFrame(rows)\n",
    "df_tool_chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a87b9de",
   "metadata": {},
   "source": [
    "### Tool efficiency averages for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a72b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tool_chains['absurd_tool_ratio'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65889b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tool_chains['absurd_tool_ratio'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d26018",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tool_chains['overall_error_rate'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2350cf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tool_chains['overall_error_rate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948b7b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tool_chains['tool_path_length_difference'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a5a07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tool_chains['tool_path_length_difference'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414b2c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tool_chains['tool_path_length_difference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0629e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tool_chains.groupby('experiment_id')['overall_error_rate'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8911c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39c3a88",
   "metadata": {},
   "source": [
    "### Combine with correctness info and analyse correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d48014",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_precise_answers['run_id'] = df_precise_answers['filename'].apply(lambda x: x.split(\"_extracted\")[0])\n",
    "df_precise_answers['run_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09493eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_merge = df_precise_answers[['run_id', 'is_correct_norm', 'is_correct_raw']]\n",
    "to_merge = to_merge.rename(columns={\"is_correct_raw\": \"is_correct_raw\"})\n",
    "to_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe16b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = (\n",
    "    df_tool_chains.merge(\n",
    "        to_merge,  \n",
    "        on=\"run_id\",\n",
    "        how=\"left\",  \n",
    "        validate=\"one_to_one\"\n",
    "    )\n",
    ")\n",
    "\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5971d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8100da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[['tool_path_length_difference', 'absurd_tool_ratio', 'overall_error_rate']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0221bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.groupby('experiment_id')[['tool_path_length_difference', 'absurd_tool_ratio', 'overall_error_rate']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20c1351",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.groupby('experiment_id')[['tool_path_length_difference', 'absurd_tool_ratio', 'overall_error_rate']].mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbab419",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['experiment_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e58d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_use_per_exp_ID = merged.groupby('experiment_id')[['tool_path_length_difference', 'absurd_tool_ratio', 'overall_error_rate']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59210f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_use_per_exp_ID.to_csv(f\"../results_analysed/tables/{model}_tool_use_per_experiment_id.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38effac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = merged[\"overall_error_rate\"].corr(merged[\"is_correct_norm\"])\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8311fafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = merged[\"tool_path_length_difference\"].corr(merged[\"is_correct_norm\"])\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4ada7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = merged[\"absurd_tool_ratio\"].corr(merged[\"is_correct_norm\"])\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a4cd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_precise_answers.groupby('experiment_id')['is_correct_norm'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd5819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = merged[\"overall_error_rate\"].corr(merged[\"tool_path_length_difference\"])\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d94df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[(merged['overall_error_rate'] == 0) & (merged['is_correct_norm'] != True)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4181e202",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[(merged['overall_error_rate'] == 0) & (merged['is_correct_norm'] == True)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e524ad42",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[(merged['overall_error_rate'] == 0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5ca4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('experiment_id == \"4-1\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a6aa2d",
   "metadata": {},
   "source": [
    "### 2026-01-08 Variance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfdb7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_precise_answers.query('experiment_id == \"5-2\" and success == True')[['filename','response','normalised_response', 'numeric_response', 'correct_answer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7c6a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_precise_answers.query('experiment_id == \"5-1\" and success == True')[['filename','response','normalised_response', 'numeric_response', 'correct_answer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d9be33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_precise_answers.query('experiment_id == \"4-1\" and success == True')['normalised_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdce559",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_precise_answers.query('experiment_id == \"4-1\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66de2cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = df_precise_answers.query('experiment_id == \"5-1\" and success == True')['normalised_response'].value_counts(normalize=True)\n",
    "gini = 1 - np.sum(p**2)\n",
    "print(gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee99148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = df_precise_answers.query('experiment_id == \"5-2\" and success == True')['normalised_response'].value_counts(normalize=True)\n",
    "gini = 1 - np.sum(p**2)\n",
    "print(gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3f78c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_precise_answers.query('success == True')[['experiment_id', 'normalised_response']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3025014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_impurity = (\n",
    "    df.groupby(\"experiment_id\")[\"normalised_response\"]\n",
    "      .apply(lambda s: 1 - np.sum(s.value_counts(normalize=True).to_numpy() ** 2))\n",
    "      .rename(\"gini_impurity\")\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "gini_impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03babc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_impurity.to_csv(f\"../results_analysed/tables/{model}_gini_impurity.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6f573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_precise_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d497cc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_precise_answers.query('experiment_id == \"2-1\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0063b831",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = (\n",
    "    df_precise_answers.groupby(\"experiment_id\")\n",
    "    .agg(\n",
    "        n_success=(\"success\", \"sum\"),\n",
    "        n_correct=(\"is_correct_norm\", \"sum\"),\n",
    "        n_unique=(\"normalised_response\", \"nunique\"),\n",
    "        gini_impurity=(\n",
    "            \"normalised_response\",\n",
    "            lambda s: 1 - np.sum(s.value_counts(normalize=True).to_numpy() ** 2)\n",
    "        )\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebc1bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.to_csv(f\"../results_analysed/tables/{model}_response_diversity_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10f110d",
   "metadata": {},
   "source": [
    "### Create updated hit and miss tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ca97fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_precise_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b88b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_miss(df_precise_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5725cb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_miss(df_precise_answers, with_emojis=False).to_csv(f\"../results_analysed/tables/hit_miss_table_{model}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deb007f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('experiment_id == \"4-1\" and success == True').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e1cfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('experiment_id == \"2-1\" and success == True').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba26afc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('experiment_id == \"3-2\" and success == True').shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
